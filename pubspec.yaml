name: llama_sdk
description: "llama_sdk is a dart implementation of llama.cpp used by the mobile artificial intelligence distribution (maid) for local model inference."
version: 0.0.6
homepage: "https://github.com/Mobile-Artificial-Intelligence/llama_sdk"

topics:
  - ai
  - chatgpt
  - llama
  - llm

environment:
  sdk: '>=3.3.0 <4.0.0'
  flutter: '>=3.3.0'

dependencies:
  ffi: ^2.1.3
  flutter:
    sdk: flutter

dev_dependencies:
  ffigen: ^13.0.0
  flutter_test:
    sdk: flutter
  flutter_lints: ^3.0.0

ffigen:
  name: 'llama'
  description: 'llama.cpp binding'
  output: 'lib/src/native/bindings.dart'
  ignore-source-errors: true
  headers:
    entry-points:
      - 'src/api.h'
  compiler-opts:
    - '-I/usr/lib/clang/17/include'

flutter:
  plugin:
    platforms:
      android:
        ffiPlugin: true
      linux:
        ffiPlugin: true
      windows:
        ffiPlugin: true
      macos:
        ffiPlugin: true
      ios:
        ffiPlugin: true

false_secrets:
  - 'src/llama_cpp/**'
